{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 322 images belonging to 4 classes.\n",
      "Found 79 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Set image dimensions and other parameters\n",
    "image_size = (224, 224)  # MobileNetV2 expects 224x224 images\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Define the paths to the dataset (adjust these paths as needed)\n",
    "base_dir = './data'  # Root directory where the 'Angry', 'Happy', 'Sad', 'Fear' folders are located\n",
    "\n",
    "# 1. **Data Augmentation**: Apply common transformations to prevent overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.5, 1.5],  # Random brightness adjustment\n",
    "    validation_split=0.2  # This will split off 20% for validation\n",
    ")\n",
    "\n",
    "# Validation and Test generators (only rescaling)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 2. **Load the data into train and validation sets using validation_split**\n",
    "train_data_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Multi-class classification (4 classes)\n",
    "    shuffle=True,\n",
    "    subset='training'  # This is the training data subset (80%)\n",
    ")\n",
    "\n",
    "val_data_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='validation'  # This is the validation data subset (20%)\n",
    ")\n",
    "\n",
    "# 3. **Use MobileNetV2 as a lighter model for smaller datasets**\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model with additional custom layers\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),  # L2 regularization\n",
    "    layers.Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    layers.Dense(4, activation='softmax')  # Output layer with 4 categories\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. **Optionally, unfreeze the last few layers for fine-tuning**\n",
    "for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers, you can adjust this number\n",
    "    layer.trainable = True\n",
    "\n",
    "# Re-compile the model after unfreezing layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Reduced learning rate for fine-tuning\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. **Setup callbacks for early stopping and model checkpointing**\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# 6. **Reduce learning rate if the validation loss does not improve**\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.3166 - loss: 12.9564 - val_accuracy: 0.4684 - val_loss: 12.5706 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5083 - loss: 12.3498 - val_accuracy: 0.5190 - val_loss: 12.2516 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 12.0590 - val_accuracy: 0.4304 - val_loss: 12.2156 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6174 - loss: 11.7995 - val_accuracy: 0.4937 - val_loss: 12.1216 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7574 - loss: 11.4409 - val_accuracy: 0.4557 - val_loss: 12.1022 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7067 - loss: 11.3275 - val_accuracy: 0.4684 - val_loss: 11.8992 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7765 - loss: 11.0605 - val_accuracy: 0.4304 - val_loss: 11.8821 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7666 - loss: 10.8763 - val_accuracy: 0.4684 - val_loss: 11.6125 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7981 - loss: 10.6548 - val_accuracy: 0.5696 - val_loss: 11.3877 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8077 - loss: 10.4614 - val_accuracy: 0.4557 - val_loss: 11.2693 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7853 - loss: 10.3835 - val_accuracy: 0.4937 - val_loss: 11.1672 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7667 - loss: 10.2728 - val_accuracy: 0.4684 - val_loss: 11.0907 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8401 - loss: 10.0118 - val_accuracy: 0.4810 - val_loss: 11.1277 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8478 - loss: 9.8550 - val_accuracy: 0.5570 - val_loss: 10.7056 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8689 - loss: 9.6653 - val_accuracy: 0.5063 - val_loss: 10.7870 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8644 - loss: 9.5420 - val_accuracy: 0.4937 - val_loss: 10.6475 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9037 - loss: 9.3281 - val_accuracy: 0.5190 - val_loss: 10.4310 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8816 - loss: 9.2136 - val_accuracy: 0.5063 - val_loss: 10.4982 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8987 - loss: 9.0856 - val_accuracy: 0.5063 - val_loss: 10.2804 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9225 - loss: 8.8710 - val_accuracy: 0.4557 - val_loss: 10.0820 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9098 - loss: 8.8042 - val_accuracy: 0.5063 - val_loss: 10.3338 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9004 - loss: 8.6575 - val_accuracy: 0.5063 - val_loss: 10.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8273 - loss: 8.6300 - val_accuracy: 0.4810 - val_loss: 9.7770 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9311 - loss: 8.3922 - val_accuracy: 0.5443 - val_loss: 9.6201 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9111 - loss: 8.2933 - val_accuracy: 0.5190 - val_loss: 9.8765 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9337 - loss: 8.1621 - val_accuracy: 0.5949 - val_loss: 9.6260 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.9206 - loss: 8.0784 - val_accuracy: 0.5316 - val_loss: 9.4964 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9131 - loss: 7.9391 - val_accuracy: 0.4810 - val_loss: 9.4222 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8769 - loss: 7.8733 - val_accuracy: 0.5570 - val_loss: 9.3708 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9359 - loss: 7.7166 - val_accuracy: 0.5063 - val_loss: 9.4954 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9446 - loss: 7.5669 - val_accuracy: 0.5316 - val_loss: 9.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9355 - loss: 7.5235 - val_accuracy: 0.5190 - val_loss: 9.1358 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9567 - loss: 7.4116 - val_accuracy: 0.5063 - val_loss: 9.0504 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9446 - loss: 7.2966 - val_accuracy: 0.5316 - val_loss: 8.9813 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9382 - loss: 7.1930 - val_accuracy: 0.5443 - val_loss: 8.6965 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9617 - loss: 7.0772 - val_accuracy: 0.5063 - val_loss: 9.2511 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9332 - loss: 7.0314 - val_accuracy: 0.4430 - val_loss: 8.9503 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9439 - loss: 6.9074 - val_accuracy: 0.4684 - val_loss: 8.9330 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9666 - loss: 6.7920 - val_accuracy: 0.5190 - val_loss: 8.6818 - learning_rate: 5.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9446 - loss: 6.7873 - val_accuracy: 0.5316 - val_loss: 8.6760 - learning_rate: 5.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9555 - loss: 6.7046 - val_accuracy: 0.3797 - val_loss: 8.9412 - learning_rate: 5.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9384 - loss: 6.6904 - val_accuracy: 0.4937 - val_loss: 8.8465 - learning_rate: 5.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9772 - loss: 6.5960 - val_accuracy: 0.4810 - val_loss: 8.4694 - learning_rate: 5.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9622 - loss: 6.6049 - val_accuracy: 0.5696 - val_loss: 8.3153 - learning_rate: 5.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.9509 - loss: 6.5534 - val_accuracy: 0.5316 - val_loss: 8.4492 - learning_rate: 5.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9525 - loss: 6.5017 - val_accuracy: 0.5190 - val_loss: 8.5524 - learning_rate: 5.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.9211 - loss: 6.5927 - val_accuracy: 0.5316 - val_loss: 8.2367 - learning_rate: 5.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9741 - loss: 6.3987 - val_accuracy: 0.4810 - val_loss: 8.2101 - learning_rate: 5.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.9448 - loss: 6.3832 - val_accuracy: 0.4937 - val_loss: 8.0592 - learning_rate: 5.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9643 - loss: 6.3217 - val_accuracy: 0.4430 - val_loss: 8.1457 - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# 7. **Train the model**\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    callbacks=[early_stop, checkpoint, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 907ms/step - accuracy: 0.4607 - loss: 7.9667\n",
      "Test accuracy: 0.4684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(val_data_gen)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
