{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set image dimensions and other parameters\n",
    "image_size = (224, 224)  # ResNet50 expects 224x224 images\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Define the paths to the dataset (adjust these paths as needed)\n",
    "base_dir = './data'  # Root directory where the 'Angry', 'Happy', 'Sad', 'Fear' folders are located\n",
    "\n",
    "# 1. **Data Augmentation**: Apply common transformations to prevent overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # This will split off 20% for validation\n",
    ")\n",
    "\n",
    "# Validation and Test generators (only rescaling)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 2. **Load the data into train and validation sets using validation_split**\n",
    "train_data_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Assuming multi-class classification (4 classes)\n",
    "    shuffle=True,\n",
    "    subset='training'  # This is the training data subset (80%)\n",
    ")\n",
    "\n",
    "val_data_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='validation'  # This is the validation data subset (20%)\n",
    ")\n",
    "\n",
    "# 3. **Define the model with ResNet50 as the base model**\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the ResNet50 model so we only train the top layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the model by adding custom layers on top of ResNet50\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(4, activation='softmax')  # Output layer with 4 categories\n",
    "])\n",
    "\n",
    "# 4. **Compile the model**\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # A low learning rate for fine-tuning\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. **Setup callbacks for early stopping and model checkpointing**\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "  \n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"./dataset\", output=\"./data-split\", seed=1337, ratio=(0.8, 0.1,0.1), group_prefix=None, move=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 482 images belonging to 4 classes.\n",
      "Found 74 images belonging to 4 classes.\n",
      "Found 138 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './dataset-split/train/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Ensure this is 'categorical' for multi-class classification\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    './dataset-split/val/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Ensure this is 'categorical' for multi-class classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 model without the top layer (for transfer learning)\n",
    "resnet_50 = ResNet50(\n",
    "    include_top=False,     # Exclude the fully connected layers\n",
    "    weights='imagenet',    # Load pre-trained ImageNet weights\n",
    "    input_shape=(224, 224, 3)  # Input image shape\n",
    ")\n",
    "\n",
    "# Freeze all layers of ResNet50 initially\n",
    "for layer in resnet_50.layers[-4:]:  # Unfreeze the last 4 layers of ResNet50\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers on top of ResNet50\n",
    "x = resnet_50.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global Average Pooling\n",
    "x = BatchNormalization()(x)      # Batch Normalization\n",
    "x = Dense(128, activation='relu')(x)  # Fully connected layer with 128 units\n",
    "x = Dropout(0.5)(x)              # Dropout layer to prevent overfitting\n",
    "\n",
    "# Output layer (softmax for 4 classes)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=resnet_50.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -89.98149  ,  -93.82149  ,  -96.72249  ],\n         [ -88.99046  ,  -92.83046  ,  -95.73146  ],\n         ...,\n         [ -31.971985 ,  -18.192192 ,   -9.299789 ],\n         [ -38.334053 ,  -25.563263 ,  -16.464264 ],\n         [ -49.65444  ,  -37.47946  ,  -28.380463 ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.405525 ,  -94.24553  ,  -97.14653  ],\n         [ -89.414505 ,  -93.2545   ,  -96.1555   ],\n         ...,\n         [ -40.45012  ,  -27.790703 ,  -18.691704 ],\n         [ -50.228188 ,  -38.26097  ,  -29.161972 ],\n         [ -52.015617 ,  -41.24002  ,  -32.14102  ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.82957  ,  -94.66956  ,  -97.570564 ],\n         [ -89.83855  ,  -93.67854  ,  -96.579544 ],\n         ...,\n         [ -50.562305 ,  -38.817833 ,  -29.718834 ],\n         [ -52.349735 ,  -41.796883 ,  -32.697884 ],\n         [ -51.74084  ,  -41.58084  ,  -32.481842 ]],\n\n        ...,\n\n        [[ -86.75221  ,  -82.779    ,  -82.68     ],\n         [ -87.93659  ,  -82.77659  ,  -82.67759  ],\n         [ -87.34078  ,  -82.18078  ,  -82.08178  ],\n         ...,\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -41.54163  ,  -79.12029  , -112.54397  ],\n         [ -25.377617 ,  -62.72234  ,  -98.12806  ]],\n\n        [[ -87.82522  ,  -82.665215 ,  -82.566216 ],\n         [ -87.22941  ,  -82.069405 ,  -81.970406 ],\n         [ -84.80117  ,  -79.64117  ,  -79.54217  ],\n         ...,\n         [ -42.633095 ,  -80.31937  , -112.60545  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -34.170822 ,  -71.182495 , -105.740135 ]],\n\n        [[ -87.118034 ,  -81.95804  ,  -81.85904  ],\n         [ -84.02157  ,  -78.861565 ,  -78.762566 ],\n         [ -79.939    ,  -74.779    ,  -74.68     ],\n         ...,\n         [ -36.272507 ,  -73.53474  , -104.12467  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -39.683327 ,  -77.11903  , -110.828606 ]]],\n\n\n       [[[ 110.38456  ,   97.54456  ,   90.64356  ],\n         [ 117.754814 ,  104.91482  ,   98.01382  ],\n         [ 118.97321  ,  106.13322  ,   99.232216 ],\n         ...,\n         [ 118.12104  ,  105.281044 ,   98.38004  ],\n         [ 119.042915 ,  106.20292  ,   99.30192  ],\n         [ 119.848564 ,  107.00857  ,  100.10757  ]],\n\n        [[ 111.05479  ,   98.21479  ,   91.31379  ],\n         [ 117.5559   ,  104.715904 ,   97.8149   ],\n         [ 124.057014 ,  111.21702  ,  104.31602  ],\n         ...,\n         [ 116.417885 ,  103.57789  ,   96.67689  ],\n         [ 116.1065   ,  103.2665   ,   96.3655   ],\n         [ 115.176384 ,  102.33639  ,   95.43539  ]],\n\n        [[ 113.06446  ,  100.224464 ,   93.32346  ],\n         [ 119.564064 ,  106.72407  ,   99.82307  ],\n         [ 126.50323  ,  113.66323  ,  106.76223  ],\n         ...,\n         [ 114.13218  ,  101.29218  ,   94.39118  ],\n         [ 112.870735 ,  100.03074  ,   93.12974  ],\n         [ 110.80599  ,   97.965996 ,   91.064995 ]],\n\n        ...,\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]]],\n\n\n       [[[  31.151436 ,   19.31144  ,   10.410439 ],\n         [  38.447853 ,   26.607857 ,   17.706856 ],\n         [  73.78977  ,   61.949776 ,   53.048775 ],\n         ...,\n         [  93.69001  ,   82.85001  ,   75.94901  ],\n         [  92.682076 ,   81.84208  ,   74.94108  ],\n         [  91.67414  ,   80.834145 ,   73.93314  ]],\n\n        [[  50.77578  ,   38.935783 ,   30.034782 ],\n         [  40.30163  ,   28.461632 ,   19.56063  ],\n         [  58.50776  ,   46.667763 ,   37.76676  ],\n         ...,\n         [  91.8292   ,   80.989204 ,   74.0882   ],\n         [  92.69314  ,   81.85314  ,   74.95214  ],\n         [  93.55709  ,   82.717094 ,   75.81609  ]],\n\n        [[  81.30981  ,   69.46981  ,   60.56881  ],\n         [  42.92936  ,   31.089363 ,   22.188362 ],\n         [  33.261864 ,   21.421867 ,   12.520866 ],\n         ...,\n         [  79.04406  ,   68.20406  ,   61.303062 ],\n         [  80.48397  ,   69.643974 ,   62.742973 ],\n         [  81.92388  ,   71.083885 ,   64.182884 ]],\n\n        ...,\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]]],\n\n\n       ...,\n\n\n       [[[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.205696 ,   83.3657   ,   74.4647   ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  93.96204  ,   84.12205  ,   75.22105  ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        ...,\n\n        [[ -69.55296  ,  -75.19606  ,  -41.69551  ],\n         [ -58.4503   ,  -62.609505 ,  -30.872086 ],\n         [ -61.80721  ,  -65.6472   ,  -34.548203 ],\n         ...,\n         [ -72.51167  ,  -77.16078  ,  -44.443565 ],\n         [ -72.03226  ,  -76.84117  ,  -43.804337 ],\n         [ -71.939    ,  -76.90772  ,  -43.422554 ]],\n\n        [[ -68.08595  ,  -73.40305  ,  -40.065506 ],\n         [ -56.657288 ,  -60.653492 ,  -29.24208  ],\n         [ -63.274216 ,  -67.11421  ,  -36.015213 ],\n         ...,\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.89541  ,  -78.74994  ,  -47.62188  ]],\n\n        [[ -66.61895  ,  -71.61005  ,  -38.435493 ],\n         [ -55.00014  ,  -58.840137 ,  -27.741135 ],\n         [ -63.939003 ,  -67.779    ,  -36.68     ],\n         ...,\n         [ -76.19684  ,  -80.036835 ,  -49.35711  ],\n         [ -75.717415 ,  -79.55741  ,  -48.71788  ],\n         [ -75.23799  ,  -79.07799  ,  -48.07865  ]]],\n\n\n       [[[  58.469154 ,  120.148186 ,  117.373344 ],\n         [ 129.83282  ,  119.33723  ,  106.830986 ],\n         [ 134.50323  ,  128.25238  ,  109.488335 ],\n         ...,\n         [ 148.768    ,  133.92801  ,  126.027016 ],\n         [ 148.12866  ,  133.28867  ,  125.38767  ],\n         [ 149.10202  ,  134.26202  ,  126.361015 ]],\n\n        [[  37.190742 ,  121.92046  ,  115.77082  ],\n         [  86.03661  ,  119.83491  ,  113.30088  ],\n         [ 138.48471  ,  121.78249  ,  106.50222  ],\n         ...,\n         [ 148.73022  ,  133.89023  ,  125.989235 ],\n         [ 148.79123  ,  133.95123  ,  126.05024  ],\n         [ 150.61026  ,  135.77026  ,  127.869255 ]],\n\n        [[  19.77179  ,  123.9112   ,  112.784706 ],\n         [  48.155083 ,  120.6674   ,  117.65041  ],\n         [ 113.60409  ,  119.521645 ,  109.2284   ],\n         ...,\n         [ 149.50964  ,  134.66965  ,  126.76864  ],\n         [ 146.92053  ,  132.08054  ,  124.17953  ],\n         [ 149.93597  ,  135.09598  ,  127.19497  ]],\n\n        ...,\n\n        [[ 146.10834  ,  129.26834  ,  121.36733  ],\n         [ 147.0217   ,  130.1817   ,  122.28069  ],\n         [ 147.93506  ,  131.09506  ,  123.19407  ],\n         ...,\n         [ 149.84198  ,   97.1641   ,   40.301308 ],\n         [ 142.20139  ,   69.824196 ,    1.6090927],\n         [ 108.14144  ,   39.008064 ,  -45.426064 ]],\n\n        [[ 147.86179  ,  131.02179  ,  123.12078  ],\n         [ 147.70392  ,  130.86392  ,  122.96293  ],\n         [ 147.24725  ,  130.40726  ,  122.50625  ],\n         ...,\n         [ 150.09634  ,   98.92501  ,   41.586617 ],\n         [ 148.58893  ,   86.8263   ,   25.89103  ],\n         [ 129.04419  ,   57.920067 ,  -16.560371 ]],\n\n        [[ 147.28387  ,  130.44388  ,  122.542885 ],\n         [ 146.82721  ,  129.98721  ,  122.086205 ],\n         [ 146.37051  ,  129.53052  ,  121.629524 ],\n         ...,\n         [ 147.60794  ,   77.52459  ,    8.739464 ],\n         [ 150.57965  ,  103.249886 ,   48.784508 ],\n         [ 147.33585  ,   76.4885   ,   11.480766 ]]],\n\n\n       [[[  58.29081  ,   76.893364 ,   79.87745  ],\n         [  61.71862  ,   79.878624 ,   81.97762  ],\n         [  65.25152  ,   83.95916  ,   84.41526  ],\n         ...,\n         [ -80.939    ,  -84.779    ,  -87.68     ],\n         [ -81.4729   ,  -85.3129   ,  -88.2139   ],\n         [ -83.866005 ,  -87.706    ,  -90.607    ]],\n\n        [[  56.343636 ,   75.432976 ,   79.39066  ],\n         [  60.258247 ,   78.41825  ,   80.51725  ],\n         [  63.304344 ,   81.525185 ,   83.44167  ],\n         ...,\n         [ -82.304276 ,  -86.14427  ,  -89.04527  ],\n         [ -84.69738  ,  -88.53738  ,  -91.43838  ],\n         [ -87.62836  ,  -91.46835  ,  -94.369354 ]],\n\n        [[  56.060997 ,   75.221    ,   80.152275 ],\n         [  58.37681  ,   76.95786  ,   79.89895  ],\n         [  61.78312  ,   79.94312  ,   82.04212  ],\n         ...,\n         [ -85.67619  ,  -89.51619  ,  -92.41719  ],\n         [ -88.66758  ,  -92.507576 ,  -95.40858  ],\n         [ -90.97098  ,  -94.810974 ,  -97.711975 ]],\n\n        ...,\n\n        [[ -93.751236 , -113.59123  , -116.42964  ],\n         [ -97.00598  , -116.71202  , -120.74698  ],\n         [ -97.60426  , -116.11374  , -121.34526  ],\n         ...,\n         [ -44.46813  ,  -32.30812  ,  -23.209122 ],\n         [ -44.710735 ,  -31.664864 ,  -24.3376   ],\n         [ -44.05805  ,  -30.89804  ,  -25.560959 ]],\n\n        [[ -97.21383  , -116.50417  , -120.95483  ],\n         [ -97.8121   , -115.9059   , -121.5531   ],\n         [ -98.88176  , -115.30762  , -122.15138  ],\n         ...,\n         [ -51.283237 ,  -39.12323  ,  -30.024231 ],\n         [ -43.73715  ,  -31.17807  ,  -22.87722  ],\n         [ -44.54484  ,  -31.384834 ,  -25.074165 ]],\n\n        [[ -98.1009   , -115.69805  , -121.76095  ],\n         [ -99.29745  , -115.09978  , -122.35922  ],\n         [-101.049    , -114.5015   , -122.68     ],\n         ...,\n         [ -56.939003 ,  -44.779    ,  -35.68     ],\n         [ -44.1671   ,  -32.007095 ,  -22.908096 ],\n         [ -44.75374  ,  -31.68637  ,  -24.402107 ]]]], dtype=float32), array([[0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -89.98149  ,  -93.82149  ,  -96.72249  ],\n         [ -88.99046  ,  -92.83046  ,  -95.73146  ],\n         ...,\n         [ -31.971985 ,  -18.192192 ,   -9.299789 ],\n         [ -38.334053 ,  -25.563263 ,  -16.464264 ],\n         [ -49.65444  ,  -37.47946  ,  -28.380463 ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.405525 ,  -94.24553  ,  -97.14653  ],\n         [ -89.414505 ,  -93.2545   ,  -96.1555   ],\n         ...,\n         [ -40.45012  ,  -27.790703 ,  -18.691704 ],\n         [ -50.228188 ,  -38.26097  ,  -29.161972 ],\n         [ -52.015617 ,  -41.24002  ,  -32.14102  ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.82957  ,  -94.66956  ,  -97.570564 ],\n         [ -89.83855  ,  -93.67854  ,  -96.579544 ],\n         ...,\n         [ -50.562305 ,  -38.817833 ,  -29.718834 ],\n         [ -52.349735 ,  -41.796883 ,  -32.697884 ],\n         [ -51.74084  ,  -41.58084  ,  -32.481842 ]],\n\n        ...,\n\n        [[ -86.75221  ,  -82.779    ,  -82.68     ],\n         [ -87.93659  ,  -82.77659  ,  -82.67759  ],\n         [ -87.34078  ,  -82.18078  ,  -82.08178  ],\n         ...,\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -41.54163  ,  -79.12029  , -112.54397  ],\n         [ -25.377617 ,  -62.72234  ,  -98.12806  ]],\n\n        [[ -87.82522  ,  -82.665215 ,  -82.566216 ],\n         [ -87.22941  ,  -82.069405 ,  -81.970406 ],\n         [ -84.80117  ,  -79.64117  ,  -79.54217  ],\n         ...,\n         [ -42.633095 ,  -80.31937  , -112.60545  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -34.170822 ,  -71.182495 , -105.740135 ]],\n\n        [[ -87.118034 ,  -81.95804  ,  -81.85904  ],\n         [ -84.02157  ,  -78.861565 ,  -78.762566 ],\n         [ -79.939    ,  -74.779    ,  -74.68     ],\n         ...,\n         [ -36.272507 ,  -73.53474  , -104.12467  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -39.683327 ,  -77.11903  , -110.828606 ]]],\n\n\n       [[[ 110.38456  ,   97.54456  ,   90.64356  ],\n         [ 117.754814 ,  104.91482  ,   98.01382  ],\n         [ 118.97321  ,  106.13322  ,   99.232216 ],\n         ...,\n         [ 118.12104  ,  105.281044 ,   98.38004  ],\n         [ 119.042915 ,  106.20292  ,   99.30192  ],\n         [ 119.848564 ,  107.00857  ,  100.10757  ]],\n\n        [[ 111.05479  ,   98.21479  ,   91.31379  ],\n         [ 117.5559   ,  104.715904 ,   97.8149   ],\n         [ 124.057014 ,  111.21702  ,  104.31602  ],\n         ...,\n         [ 116.417885 ,  103.57789  ,   96.67689  ],\n         [ 116.1065   ,  103.2665   ,   96.3655   ],\n         [ 115.176384 ,  102.33639  ,   95.43539  ]],\n\n        [[ 113.06446  ,  100.224464 ,   93.32346  ],\n         [ 119.564064 ,  106.72407  ,   99.82307  ],\n         [ 126.50323  ,  113.66323  ,  106.76223  ],\n         ...,\n         [ 114.13218  ,  101.29218  ,   94.39118  ],\n         [ 112.870735 ,  100.03074  ,   93.12974  ],\n         [ 110.80599  ,   97.965996 ,   91.064995 ]],\n\n        ...,\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]]],\n\n\n       [[[  31.151436 ,   19.31144  ,   10.410439 ],\n         [  38.447853 ,   26.607857 ,   17.706856 ],\n         [  73.78977  ,   61.949776 ,   53.048775 ],\n         ...,\n         [  93.69001  ,   82.85001  ,   75.94901  ],\n         [  92.682076 ,   81.84208  ,   74.94108  ],\n         [  91.67414  ,   80.834145 ,   73.93314  ]],\n\n        [[  50.77578  ,   38.935783 ,   30.034782 ],\n         [  40.30163  ,   28.461632 ,   19.56063  ],\n         [  58.50776  ,   46.667763 ,   37.76676  ],\n         ...,\n         [  91.8292   ,   80.989204 ,   74.0882   ],\n         [  92.69314  ,   81.85314  ,   74.95214  ],\n         [  93.55709  ,   82.717094 ,   75.81609  ]],\n\n        [[  81.30981  ,   69.46981  ,   60.56881  ],\n         [  42.92936  ,   31.089363 ,   22.188362 ],\n         [  33.261864 ,   21.421867 ,   12.520866 ],\n         ...,\n         [  79.04406  ,   68.20406  ,   61.303062 ],\n         [  80.48397  ,   69.643974 ,   62.742973 ],\n         [  81.92388  ,   71.083885 ,   64.182884 ]],\n\n        ...,\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]]],\n\n\n       ...,\n\n\n       [[[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.205696 ,   83.3657   ,   74.4647   ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  93.96204  ,   84.12205  ,   75.22105  ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        ...,\n\n        [[ -69.55296  ,  -75.19606  ,  -41.69551  ],\n         [ -58.4503   ,  -62.609505 ,  -30.872086 ],\n         [ -61.80721  ,  -65.6472   ,  -34.548203 ],\n         ...,\n         [ -72.51167  ,  -77.16078  ,  -44.443565 ],\n         [ -72.03226  ,  -76.84117  ,  -43.804337 ],\n         [ -71.939    ,  -76.90772  ,  -43.422554 ]],\n\n        [[ -68.08595  ,  -73.40305  ,  -40.065506 ],\n         [ -56.657288 ,  -60.653492 ,  -29.24208  ],\n         [ -63.274216 ,  -67.11421  ,  -36.015213 ],\n         ...,\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.89541  ,  -78.74994  ,  -47.62188  ]],\n\n        [[ -66.61895  ,  -71.61005  ,  -38.435493 ],\n         [ -55.00014  ,  -58.840137 ,  -27.741135 ],\n         [ -63.939003 ,  -67.779    ,  -36.68     ],\n         ...,\n         [ -76.19684  ,  -80.036835 ,  -49.35711  ],\n         [ -75.717415 ,  -79.55741  ,  -48.71788  ],\n         [ -75.23799  ,  -79.07799  ,  -48.07865  ]]],\n\n\n       [[[  58.469154 ,  120.148186 ,  117.373344 ],\n         [ 129.83282  ,  119.33723  ,  106.830986 ],\n         [ 134.50323  ,  128.25238  ,  109.488335 ],\n         ...,\n         [ 148.768    ,  133.92801  ,  126.027016 ],\n         [ 148.12866  ,  133.28867  ,  125.38767  ],\n         [ 149.10202  ,  134.26202  ,  126.361015 ]],\n\n        [[  37.190742 ,  121.92046  ,  115.77082  ],\n         [  86.03661  ,  119.83491  ,  113.30088  ],\n         [ 138.48471  ,  121.78249  ,  106.50222  ],\n         ...,\n         [ 148.73022  ,  133.89023  ,  125.989235 ],\n         [ 148.79123  ,  133.95123  ,  126.05024  ],\n         [ 150.61026  ,  135.77026  ,  127.869255 ]],\n\n        [[  19.77179  ,  123.9112   ,  112.784706 ],\n         [  48.155083 ,  120.6674   ,  117.65041  ],\n         [ 113.60409  ,  119.521645 ,  109.2284   ],\n         ...,\n         [ 149.50964  ,  134.66965  ,  126.76864  ],\n         [ 146.92053  ,  132.08054  ,  124.17953  ],\n         [ 149.93597  ,  135.09598  ,  127.19497  ]],\n\n        ...,\n\n        [[ 146.10834  ,  129.26834  ,  121.36733  ],\n         [ 147.0217   ,  130.1817   ,  122.28069  ],\n         [ 147.93506  ,  131.09506  ,  123.19407  ],\n         ...,\n         [ 149.84198  ,   97.1641   ,   40.301308 ],\n         [ 142.20139  ,   69.824196 ,    1.6090927],\n         [ 108.14144  ,   39.008064 ,  -45.426064 ]],\n\n        [[ 147.86179  ,  131.02179  ,  123.12078  ],\n         [ 147.70392  ,  130.86392  ,  122.96293  ],\n         [ 147.24725  ,  130.40726  ,  122.50625  ],\n         ...,\n         [ 150.09634  ,   98.92501  ,   41.586617 ],\n         [ 148.58893  ,   86.8263   ,   25.89103  ],\n         [ 129.04419  ,   57.920067 ,  -16.560371 ]],\n\n        [[ 147.28387  ,  130.44388  ,  122.542885 ],\n         [ 146.82721  ,  129.98721  ,  122.086205 ],\n         [ 146.37051  ,  129.53052  ,  121.629524 ],\n         ...,\n         [ 147.60794  ,   77.52459  ,    8.739464 ],\n         [ 150.57965  ,  103.249886 ,   48.784508 ],\n         [ 147.33585  ,   76.4885   ,   11.480766 ]]],\n\n\n       [[[  58.29081  ,   76.893364 ,   79.87745  ],\n         [  61.71862  ,   79.878624 ,   81.97762  ],\n         [  65.25152  ,   83.95916  ,   84.41526  ],\n         ...,\n         [ -80.939    ,  -84.779    ,  -87.68     ],\n         [ -81.4729   ,  -85.3129   ,  -88.2139   ],\n         [ -83.866005 ,  -87.706    ,  -90.607    ]],\n\n        [[  56.343636 ,   75.432976 ,   79.39066  ],\n         [  60.258247 ,   78.41825  ,   80.51725  ],\n         [  63.304344 ,   81.525185 ,   83.44167  ],\n         ...,\n         [ -82.304276 ,  -86.14427  ,  -89.04527  ],\n         [ -84.69738  ,  -88.53738  ,  -91.43838  ],\n         [ -87.62836  ,  -91.46835  ,  -94.369354 ]],\n\n        [[  56.060997 ,   75.221    ,   80.152275 ],\n         [  58.37681  ,   76.95786  ,   79.89895  ],\n         [  61.78312  ,   79.94312  ,   82.04212  ],\n         ...,\n         [ -85.67619  ,  -89.51619  ,  -92.41719  ],\n         [ -88.66758  ,  -92.507576 ,  -95.40858  ],\n         [ -90.97098  ,  -94.810974 ,  -97.711975 ]],\n\n        ...,\n\n        [[ -93.751236 , -113.59123  , -116.42964  ],\n         [ -97.00598  , -116.71202  , -120.74698  ],\n         [ -97.60426  , -116.11374  , -121.34526  ],\n         ...,\n         [ -44.46813  ,  -32.30812  ,  -23.209122 ],\n         [ -44.710735 ,  -31.664864 ,  -24.3376   ],\n         [ -44.05805  ,  -30.89804  ,  -25.560959 ]],\n\n        [[ -97.21383  , -116.50417  , -120.95483  ],\n         [ -97.8121   , -115.9059   , -121.5531   ],\n         [ -98.88176  , -115.30762  , -122.15138  ],\n         ...,\n         [ -51.283237 ,  -39.12323  ,  -30.024231 ],\n         [ -43.73715  ,  -31.17807  ,  -22.87722  ],\n         [ -44.54484  ,  -31.384834 ,  -25.074165 ]],\n\n        [[ -98.1009   , -115.69805  , -121.76095  ],\n         [ -99.29745  , -115.09978  , -122.35922  ],\n         [-101.049    , -114.5015   , -122.68     ],\n         ...,\n         [ -56.939003 ,  -44.779    ,  -35.68     ],\n         [ -44.1671   ,  -32.007095 ,  -22.908096 ],\n         [ -44.75374  ,  -31.68637  ,  -24.402107 ]]]], dtype=float32), array([[0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_45323]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m2.\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;241m2.\u001b[39m}\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Call the trainModel function\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, train_generator, valid_generator, epochs, class_weights)\u001b[0m\n\u001b[0;32m      9\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model with class weights if provided\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include class weights\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -89.98149  ,  -93.82149  ,  -96.72249  ],\n         [ -88.99046  ,  -92.83046  ,  -95.73146  ],\n         ...,\n         [ -31.971985 ,  -18.192192 ,   -9.299789 ],\n         [ -38.334053 ,  -25.563263 ,  -16.464264 ],\n         [ -49.65444  ,  -37.47946  ,  -28.380463 ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.405525 ,  -94.24553  ,  -97.14653  ],\n         [ -89.414505 ,  -93.2545   ,  -96.1555   ],\n         ...,\n         [ -40.45012  ,  -27.790703 ,  -18.691704 ],\n         [ -50.228188 ,  -38.26097  ,  -29.161972 ],\n         [ -52.015617 ,  -41.24002  ,  -32.14102  ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.82957  ,  -94.66956  ,  -97.570564 ],\n         [ -89.83855  ,  -93.67854  ,  -96.579544 ],\n         ...,\n         [ -50.562305 ,  -38.817833 ,  -29.718834 ],\n         [ -52.349735 ,  -41.796883 ,  -32.697884 ],\n         [ -51.74084  ,  -41.58084  ,  -32.481842 ]],\n\n        ...,\n\n        [[ -86.75221  ,  -82.779    ,  -82.68     ],\n         [ -87.93659  ,  -82.77659  ,  -82.67759  ],\n         [ -87.34078  ,  -82.18078  ,  -82.08178  ],\n         ...,\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -41.54163  ,  -79.12029  , -112.54397  ],\n         [ -25.377617 ,  -62.72234  ,  -98.12806  ]],\n\n        [[ -87.82522  ,  -82.665215 ,  -82.566216 ],\n         [ -87.22941  ,  -82.069405 ,  -81.970406 ],\n         [ -84.80117  ,  -79.64117  ,  -79.54217  ],\n         ...,\n         [ -42.633095 ,  -80.31937  , -112.60545  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -34.170822 ,  -71.182495 , -105.740135 ]],\n\n        [[ -87.118034 ,  -81.95804  ,  -81.85904  ],\n         [ -84.02157  ,  -78.861565 ,  -78.762566 ],\n         [ -79.939    ,  -74.779    ,  -74.68     ],\n         ...,\n         [ -36.272507 ,  -73.53474  , -104.12467  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -39.683327 ,  -77.11903  , -110.828606 ]]],\n\n\n       [[[ 110.38456  ,   97.54456  ,   90.64356  ],\n         [ 117.754814 ,  104.91482  ,   98.01382  ],\n         [ 118.97321  ,  106.13322  ,   99.232216 ],\n         ...,\n         [ 118.12104  ,  105.281044 ,   98.38004  ],\n         [ 119.042915 ,  106.20292  ,   99.30192  ],\n         [ 119.848564 ,  107.00857  ,  100.10757  ]],\n\n        [[ 111.05479  ,   98.21479  ,   91.31379  ],\n         [ 117.5559   ,  104.715904 ,   97.8149   ],\n         [ 124.057014 ,  111.21702  ,  104.31602  ],\n         ...,\n         [ 116.417885 ,  103.57789  ,   96.67689  ],\n         [ 116.1065   ,  103.2665   ,   96.3655   ],\n         [ 115.176384 ,  102.33639  ,   95.43539  ]],\n\n        [[ 113.06446  ,  100.224464 ,   93.32346  ],\n         [ 119.564064 ,  106.72407  ,   99.82307  ],\n         [ 126.50323  ,  113.66323  ,  106.76223  ],\n         ...,\n         [ 114.13218  ,  101.29218  ,   94.39118  ],\n         [ 112.870735 ,  100.03074  ,   93.12974  ],\n         [ 110.80599  ,   97.965996 ,   91.064995 ]],\n\n        ...,\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]]],\n\n\n       [[[  31.151436 ,   19.31144  ,   10.410439 ],\n         [  38.447853 ,   26.607857 ,   17.706856 ],\n         [  73.78977  ,   61.949776 ,   53.048775 ],\n         ...,\n         [  93.69001  ,   82.85001  ,   75.94901  ],\n         [  92.682076 ,   81.84208  ,   74.94108  ],\n         [  91.67414  ,   80.834145 ,   73.93314  ]],\n\n        [[  50.77578  ,   38.935783 ,   30.034782 ],\n         [  40.30163  ,   28.461632 ,   19.56063  ],\n         [  58.50776  ,   46.667763 ,   37.76676  ],\n         ...,\n         [  91.8292   ,   80.989204 ,   74.0882   ],\n         [  92.69314  ,   81.85314  ,   74.95214  ],\n         [  93.55709  ,   82.717094 ,   75.81609  ]],\n\n        [[  81.30981  ,   69.46981  ,   60.56881  ],\n         [  42.92936  ,   31.089363 ,   22.188362 ],\n         [  33.261864 ,   21.421867 ,   12.520866 ],\n         ...,\n         [  79.04406  ,   68.20406  ,   61.303062 ],\n         [  80.48397  ,   69.643974 ,   62.742973 ],\n         [  81.92388  ,   71.083885 ,   64.182884 ]],\n\n        ...,\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]]],\n\n\n       ...,\n\n\n       [[[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.205696 ,   83.3657   ,   74.4647   ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  93.96204  ,   84.12205  ,   75.22105  ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        ...,\n\n        [[ -69.55296  ,  -75.19606  ,  -41.69551  ],\n         [ -58.4503   ,  -62.609505 ,  -30.872086 ],\n         [ -61.80721  ,  -65.6472   ,  -34.548203 ],\n         ...,\n         [ -72.51167  ,  -77.16078  ,  -44.443565 ],\n         [ -72.03226  ,  -76.84117  ,  -43.804337 ],\n         [ -71.939    ,  -76.90772  ,  -43.422554 ]],\n\n        [[ -68.08595  ,  -73.40305  ,  -40.065506 ],\n         [ -56.657288 ,  -60.653492 ,  -29.24208  ],\n         [ -63.274216 ,  -67.11421  ,  -36.015213 ],\n         ...,\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.89541  ,  -78.74994  ,  -47.62188  ]],\n\n        [[ -66.61895  ,  -71.61005  ,  -38.435493 ],\n         [ -55.00014  ,  -58.840137 ,  -27.741135 ],\n         [ -63.939003 ,  -67.779    ,  -36.68     ],\n         ...,\n         [ -76.19684  ,  -80.036835 ,  -49.35711  ],\n         [ -75.717415 ,  -79.55741  ,  -48.71788  ],\n         [ -75.23799  ,  -79.07799  ,  -48.07865  ]]],\n\n\n       [[[  58.469154 ,  120.148186 ,  117.373344 ],\n         [ 129.83282  ,  119.33723  ,  106.830986 ],\n         [ 134.50323  ,  128.25238  ,  109.488335 ],\n         ...,\n         [ 148.768    ,  133.92801  ,  126.027016 ],\n         [ 148.12866  ,  133.28867  ,  125.38767  ],\n         [ 149.10202  ,  134.26202  ,  126.361015 ]],\n\n        [[  37.190742 ,  121.92046  ,  115.77082  ],\n         [  86.03661  ,  119.83491  ,  113.30088  ],\n         [ 138.48471  ,  121.78249  ,  106.50222  ],\n         ...,\n         [ 148.73022  ,  133.89023  ,  125.989235 ],\n         [ 148.79123  ,  133.95123  ,  126.05024  ],\n         [ 150.61026  ,  135.77026  ,  127.869255 ]],\n\n        [[  19.77179  ,  123.9112   ,  112.784706 ],\n         [  48.155083 ,  120.6674   ,  117.65041  ],\n         [ 113.60409  ,  119.521645 ,  109.2284   ],\n         ...,\n         [ 149.50964  ,  134.66965  ,  126.76864  ],\n         [ 146.92053  ,  132.08054  ,  124.17953  ],\n         [ 149.93597  ,  135.09598  ,  127.19497  ]],\n\n        ...,\n\n        [[ 146.10834  ,  129.26834  ,  121.36733  ],\n         [ 147.0217   ,  130.1817   ,  122.28069  ],\n         [ 147.93506  ,  131.09506  ,  123.19407  ],\n         ...,\n         [ 149.84198  ,   97.1641   ,   40.301308 ],\n         [ 142.20139  ,   69.824196 ,    1.6090927],\n         [ 108.14144  ,   39.008064 ,  -45.426064 ]],\n\n        [[ 147.86179  ,  131.02179  ,  123.12078  ],\n         [ 147.70392  ,  130.86392  ,  122.96293  ],\n         [ 147.24725  ,  130.40726  ,  122.50625  ],\n         ...,\n         [ 150.09634  ,   98.92501  ,   41.586617 ],\n         [ 148.58893  ,   86.8263   ,   25.89103  ],\n         [ 129.04419  ,   57.920067 ,  -16.560371 ]],\n\n        [[ 147.28387  ,  130.44388  ,  122.542885 ],\n         [ 146.82721  ,  129.98721  ,  122.086205 ],\n         [ 146.37051  ,  129.53052  ,  121.629524 ],\n         ...,\n         [ 147.60794  ,   77.52459  ,    8.739464 ],\n         [ 150.57965  ,  103.249886 ,   48.784508 ],\n         [ 147.33585  ,   76.4885   ,   11.480766 ]]],\n\n\n       [[[  58.29081  ,   76.893364 ,   79.87745  ],\n         [  61.71862  ,   79.878624 ,   81.97762  ],\n         [  65.25152  ,   83.95916  ,   84.41526  ],\n         ...,\n         [ -80.939    ,  -84.779    ,  -87.68     ],\n         [ -81.4729   ,  -85.3129   ,  -88.2139   ],\n         [ -83.866005 ,  -87.706    ,  -90.607    ]],\n\n        [[  56.343636 ,   75.432976 ,   79.39066  ],\n         [  60.258247 ,   78.41825  ,   80.51725  ],\n         [  63.304344 ,   81.525185 ,   83.44167  ],\n         ...,\n         [ -82.304276 ,  -86.14427  ,  -89.04527  ],\n         [ -84.69738  ,  -88.53738  ,  -91.43838  ],\n         [ -87.62836  ,  -91.46835  ,  -94.369354 ]],\n\n        [[  56.060997 ,   75.221    ,   80.152275 ],\n         [  58.37681  ,   76.95786  ,   79.89895  ],\n         [  61.78312  ,   79.94312  ,   82.04212  ],\n         ...,\n         [ -85.67619  ,  -89.51619  ,  -92.41719  ],\n         [ -88.66758  ,  -92.507576 ,  -95.40858  ],\n         [ -90.97098  ,  -94.810974 ,  -97.711975 ]],\n\n        ...,\n\n        [[ -93.751236 , -113.59123  , -116.42964  ],\n         [ -97.00598  , -116.71202  , -120.74698  ],\n         [ -97.60426  , -116.11374  , -121.34526  ],\n         ...,\n         [ -44.46813  ,  -32.30812  ,  -23.209122 ],\n         [ -44.710735 ,  -31.664864 ,  -24.3376   ],\n         [ -44.05805  ,  -30.89804  ,  -25.560959 ]],\n\n        [[ -97.21383  , -116.50417  , -120.95483  ],\n         [ -97.8121   , -115.9059   , -121.5531   ],\n         [ -98.88176  , -115.30762  , -122.15138  ],\n         ...,\n         [ -51.283237 ,  -39.12323  ,  -30.024231 ],\n         [ -43.73715  ,  -31.17807  ,  -22.87722  ],\n         [ -44.54484  ,  -31.384834 ,  -25.074165 ]],\n\n        [[ -98.1009   , -115.69805  , -121.76095  ],\n         [ -99.29745  , -115.09978  , -122.35922  ],\n         [-101.049    , -114.5015   , -122.68     ],\n         ...,\n         [ -56.939003 ,  -44.779    ,  -35.68     ],\n         [ -44.1671   ,  -32.007095 ,  -22.908096 ],\n         [ -44.75374  ,  -31.68637  ,  -24.402107 ]]]], dtype=float32), array([[0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.]], dtype=float32)).\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1427, in _tf_data_assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.float32), but the yielded element was (array([[[[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -89.98149  ,  -93.82149  ,  -96.72249  ],\n         [ -88.99046  ,  -92.83046  ,  -95.73146  ],\n         ...,\n         [ -31.971985 ,  -18.192192 ,   -9.299789 ],\n         [ -38.334053 ,  -25.563263 ,  -16.464264 ],\n         [ -49.65444  ,  -37.47946  ,  -28.380463 ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.405525 ,  -94.24553  ,  -97.14653  ],\n         [ -89.414505 ,  -93.2545   ,  -96.1555   ],\n         ...,\n         [ -40.45012  ,  -27.790703 ,  -18.691704 ],\n         [ -50.228188 ,  -38.26097  ,  -29.161972 ],\n         [ -52.015617 ,  -41.24002  ,  -32.14102  ]],\n\n        [[ -90.939    ,  -94.779    ,  -97.68     ],\n         [ -90.82957  ,  -94.66956  ,  -97.570564 ],\n         [ -89.83855  ,  -93.67854  ,  -96.579544 ],\n         ...,\n         [ -50.562305 ,  -38.817833 ,  -29.718834 ],\n         [ -52.349735 ,  -41.796883 ,  -32.697884 ],\n         [ -51.74084  ,  -41.58084  ,  -32.481842 ]],\n\n        ...,\n\n        [[ -86.75221  ,  -82.779    ,  -82.68     ],\n         [ -87.93659  ,  -82.77659  ,  -82.67759  ],\n         [ -87.34078  ,  -82.18078  ,  -82.08178  ],\n         ...,\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -41.54163  ,  -79.12029  , -112.54397  ],\n         [ -25.377617 ,  -62.72234  ,  -98.12806  ]],\n\n        [[ -87.82522  ,  -82.665215 ,  -82.566216 ],\n         [ -87.22941  ,  -82.069405 ,  -81.970406 ],\n         [ -84.80117  ,  -79.64117  ,  -79.54217  ],\n         ...,\n         [ -42.633095 ,  -80.31937  , -112.60545  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -34.170822 ,  -71.182495 , -105.740135 ]],\n\n        [[ -87.118034 ,  -81.95804  ,  -81.85904  ],\n         [ -84.02157  ,  -78.861565 ,  -78.762566 ],\n         [ -79.939    ,  -74.779    ,  -74.68     ],\n         ...,\n         [ -36.272507 ,  -73.53474  , -104.12467  ],\n         [ -44.939003 ,  -82.779    , -115.68     ],\n         [ -39.683327 ,  -77.11903  , -110.828606 ]]],\n\n\n       [[[ 110.38456  ,   97.54456  ,   90.64356  ],\n         [ 117.754814 ,  104.91482  ,   98.01382  ],\n         [ 118.97321  ,  106.13322  ,   99.232216 ],\n         ...,\n         [ 118.12104  ,  105.281044 ,   98.38004  ],\n         [ 119.042915 ,  106.20292  ,   99.30192  ],\n         [ 119.848564 ,  107.00857  ,  100.10757  ]],\n\n        [[ 111.05479  ,   98.21479  ,   91.31379  ],\n         [ 117.5559   ,  104.715904 ,   97.8149   ],\n         [ 124.057014 ,  111.21702  ,  104.31602  ],\n         ...,\n         [ 116.417885 ,  103.57789  ,   96.67689  ],\n         [ 116.1065   ,  103.2665   ,   96.3655   ],\n         [ 115.176384 ,  102.33639  ,   95.43539  ]],\n\n        [[ 113.06446  ,  100.224464 ,   93.32346  ],\n         [ 119.564064 ,  106.72407  ,   99.82307  ],\n         [ 126.50323  ,  113.66323  ,  106.76223  ],\n         ...,\n         [ 114.13218  ,  101.29218  ,   94.39118  ],\n         [ 112.870735 ,  100.03074  ,   93.12974  ],\n         [ 110.80599  ,   97.965996 ,   91.064995 ]],\n\n        ...,\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]],\n\n        [[ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         ...,\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ],\n         [ 151.061    ,  138.22101  ,  131.32     ]]],\n\n\n       [[[  31.151436 ,   19.31144  ,   10.410439 ],\n         [  38.447853 ,   26.607857 ,   17.706856 ],\n         [  73.78977  ,   61.949776 ,   53.048775 ],\n         ...,\n         [  93.69001  ,   82.85001  ,   75.94901  ],\n         [  92.682076 ,   81.84208  ,   74.94108  ],\n         [  91.67414  ,   80.834145 ,   73.93314  ]],\n\n        [[  50.77578  ,   38.935783 ,   30.034782 ],\n         [  40.30163  ,   28.461632 ,   19.56063  ],\n         [  58.50776  ,   46.667763 ,   37.76676  ],\n         ...,\n         [  91.8292   ,   80.989204 ,   74.0882   ],\n         [  92.69314  ,   81.85314  ,   74.95214  ],\n         [  93.55709  ,   82.717094 ,   75.81609  ]],\n\n        [[  81.30981  ,   69.46981  ,   60.56881  ],\n         [  42.92936  ,   31.089363 ,   22.188362 ],\n         [  33.261864 ,   21.421867 ,   12.520866 ],\n         ...,\n         [  79.04406  ,   68.20406  ,   61.303062 ],\n         [  80.48397  ,   69.643974 ,   62.742973 ],\n         [  81.92388  ,   71.083885 ,   64.182884 ]],\n\n        ...,\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]],\n\n        [[ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         ...,\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ],\n         [ -46.939003 ,  -69.779    ,  -83.68     ]]],\n\n\n       ...,\n\n\n       [[[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.205696 ,   83.3657   ,   74.4647   ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  94.061    ,   84.221    ,   75.32     ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        [[ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         [ 130.061    ,  120.221    ,  111.32     ],\n         ...,\n         [  93.96204  ,   84.12205  ,   75.22105  ],\n         [  93.061    ,   83.221    ,   74.32     ],\n         [  93.061    ,   83.221    ,   74.32     ]],\n\n        ...,\n\n        [[ -69.55296  ,  -75.19606  ,  -41.69551  ],\n         [ -58.4503   ,  -62.609505 ,  -30.872086 ],\n         [ -61.80721  ,  -65.6472   ,  -34.548203 ],\n         ...,\n         [ -72.51167  ,  -77.16078  ,  -44.443565 ],\n         [ -72.03226  ,  -76.84117  ,  -43.804337 ],\n         [ -71.939    ,  -76.90772  ,  -43.422554 ]],\n\n        [[ -68.08595  ,  -73.40305  ,  -40.065506 ],\n         [ -56.657288 ,  -60.653492 ,  -29.24208  ],\n         [ -63.274216 ,  -67.11421  ,  -36.015213 ],\n         ...,\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.939    ,  -78.779    ,  -47.68     ],\n         [ -74.89541  ,  -78.74994  ,  -47.62188  ]],\n\n        [[ -66.61895  ,  -71.61005  ,  -38.435493 ],\n         [ -55.00014  ,  -58.840137 ,  -27.741135 ],\n         [ -63.939003 ,  -67.779    ,  -36.68     ],\n         ...,\n         [ -76.19684  ,  -80.036835 ,  -49.35711  ],\n         [ -75.717415 ,  -79.55741  ,  -48.71788  ],\n         [ -75.23799  ,  -79.07799  ,  -48.07865  ]]],\n\n\n       [[[  58.469154 ,  120.148186 ,  117.373344 ],\n         [ 129.83282  ,  119.33723  ,  106.830986 ],\n         [ 134.50323  ,  128.25238  ,  109.488335 ],\n         ...,\n         [ 148.768    ,  133.92801  ,  126.027016 ],\n         [ 148.12866  ,  133.28867  ,  125.38767  ],\n         [ 149.10202  ,  134.26202  ,  126.361015 ]],\n\n        [[  37.190742 ,  121.92046  ,  115.77082  ],\n         [  86.03661  ,  119.83491  ,  113.30088  ],\n         [ 138.48471  ,  121.78249  ,  106.50222  ],\n         ...,\n         [ 148.73022  ,  133.89023  ,  125.989235 ],\n         [ 148.79123  ,  133.95123  ,  126.05024  ],\n         [ 150.61026  ,  135.77026  ,  127.869255 ]],\n\n        [[  19.77179  ,  123.9112   ,  112.784706 ],\n         [  48.155083 ,  120.6674   ,  117.65041  ],\n         [ 113.60409  ,  119.521645 ,  109.2284   ],\n         ...,\n         [ 149.50964  ,  134.66965  ,  126.76864  ],\n         [ 146.92053  ,  132.08054  ,  124.17953  ],\n         [ 149.93597  ,  135.09598  ,  127.19497  ]],\n\n        ...,\n\n        [[ 146.10834  ,  129.26834  ,  121.36733  ],\n         [ 147.0217   ,  130.1817   ,  122.28069  ],\n         [ 147.93506  ,  131.09506  ,  123.19407  ],\n         ...,\n         [ 149.84198  ,   97.1641   ,   40.301308 ],\n         [ 142.20139  ,   69.824196 ,    1.6090927],\n         [ 108.14144  ,   39.008064 ,  -45.426064 ]],\n\n        [[ 147.86179  ,  131.02179  ,  123.12078  ],\n         [ 147.70392  ,  130.86392  ,  122.96293  ],\n         [ 147.24725  ,  130.40726  ,  122.50625  ],\n         ...,\n         [ 150.09634  ,   98.92501  ,   41.586617 ],\n         [ 148.58893  ,   86.8263   ,   25.89103  ],\n         [ 129.04419  ,   57.920067 ,  -16.560371 ]],\n\n        [[ 147.28387  ,  130.44388  ,  122.542885 ],\n         [ 146.82721  ,  129.98721  ,  122.086205 ],\n         [ 146.37051  ,  129.53052  ,  121.629524 ],\n         ...,\n         [ 147.60794  ,   77.52459  ,    8.739464 ],\n         [ 150.57965  ,  103.249886 ,   48.784508 ],\n         [ 147.33585  ,   76.4885   ,   11.480766 ]]],\n\n\n       [[[  58.29081  ,   76.893364 ,   79.87745  ],\n         [  61.71862  ,   79.878624 ,   81.97762  ],\n         [  65.25152  ,   83.95916  ,   84.41526  ],\n         ...,\n         [ -80.939    ,  -84.779    ,  -87.68     ],\n         [ -81.4729   ,  -85.3129   ,  -88.2139   ],\n         [ -83.866005 ,  -87.706    ,  -90.607    ]],\n\n        [[  56.343636 ,   75.432976 ,   79.39066  ],\n         [  60.258247 ,   78.41825  ,   80.51725  ],\n         [  63.304344 ,   81.525185 ,   83.44167  ],\n         ...,\n         [ -82.304276 ,  -86.14427  ,  -89.04527  ],\n         [ -84.69738  ,  -88.53738  ,  -91.43838  ],\n         [ -87.62836  ,  -91.46835  ,  -94.369354 ]],\n\n        [[  56.060997 ,   75.221    ,   80.152275 ],\n         [  58.37681  ,   76.95786  ,   79.89895  ],\n         [  61.78312  ,   79.94312  ,   82.04212  ],\n         ...,\n         [ -85.67619  ,  -89.51619  ,  -92.41719  ],\n         [ -88.66758  ,  -92.507576 ,  -95.40858  ],\n         [ -90.97098  ,  -94.810974 ,  -97.711975 ]],\n\n        ...,\n\n        [[ -93.751236 , -113.59123  , -116.42964  ],\n         [ -97.00598  , -116.71202  , -120.74698  ],\n         [ -97.60426  , -116.11374  , -121.34526  ],\n         ...,\n         [ -44.46813  ,  -32.30812  ,  -23.209122 ],\n         [ -44.710735 ,  -31.664864 ,  -24.3376   ],\n         [ -44.05805  ,  -30.89804  ,  -25.560959 ]],\n\n        [[ -97.21383  , -116.50417  , -120.95483  ],\n         [ -97.8121   , -115.9059   , -121.5531   ],\n         [ -98.88176  , -115.30762  , -122.15138  ],\n         ...,\n         [ -51.283237 ,  -39.12323  ,  -30.024231 ],\n         [ -43.73715  ,  -31.17807  ,  -22.87722  ],\n         [ -44.54484  ,  -31.384834 ,  -25.074165 ]],\n\n        [[ -98.1009   , -115.69805  , -121.76095  ],\n         [ -99.29745  , -115.09978  , -122.35922  ],\n         [-101.049    , -114.5015   , -122.68     ],\n         ...,\n         [ -56.939003 ,  -44.779    ,  -35.68     ],\n         [ -44.1671   ,  -32.007095 ,  -22.908096 ],\n         [ -44.75374  ,  -31.68637  ,  -24.402107 ]]]], dtype=float32), array([[0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.]], dtype=float32)).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_45323]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Function to train the model\n",
    "def trainModel(model, train_generator, valid_generator, epochs, class_weights=None):\n",
    "    batch_size = 32\n",
    "    \n",
    "    # Callbacks to stop training early and reduce learning rate\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "    \n",
    "    # Train the model with class weights if provided\n",
    "    return model.fit(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weights,  # Include class weights\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "# Define class weights (adjust based on your dataset)\n",
    "class_weights = {0: 1., 1: 1., 2: 2., 3: 2.}\n",
    "\n",
    "# Call the trainModel function\n",
    "model_history = trainModel(\n",
    "    model=model, \n",
    "    train_generator=train_generator, \n",
    "    valid_generator=valid_generator, \n",
    "    epochs=50, \n",
    "    class_weights=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 4s - 1s/step - accuracy: 0.5541 - loss: 1.3819\n",
      "Test Accuracy: 0.5540540814399719\n",
      "Test Loss: 1.3819315433502197\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
